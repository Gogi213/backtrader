# ĞœĞµÑ‚Ğ¾Ğ´Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ¾Ğ¹ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¢Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ñ… Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹

**ĞĞ²Ñ‚Ğ¾Ñ€:** Claude Code
**Ğ”Ğ°Ñ‚Ğ°:** 2025-10-11
**Ğ¦ĞµĞ»ÑŒ:** Ğ˜Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ overfitting Ğ¸ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

---

## Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ

1. [ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ñ‚Ğ²Ğ¾Ğ¹ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚](#Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°)
2. [Walk-Forward Optimization (WFO) â€” Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾](#wfo-Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾)
3. [Temporal Validation Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸](#temporal-validation)
4. [Cross-Symbol Ensemble](#cross-symbol-ensemble)
5. [ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Pipeline Ğ´Ğ»Ñ 63 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ²](#pipeline)
6. [ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸](#Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸)
7. [ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ](#Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ)
8. [Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²](#Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ)
9. [Ğ§ĞµĞºĞ»Ğ¸ÑÑ‚ Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹](#Ñ‡ĞµĞºĞ»Ğ¸ÑÑ‚)

---

<a name="Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°"></a>
## 1. ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ñ‚Ğ²Ğ¾Ğ¹ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚

### Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ (ĞĞ• Ğ ĞĞ‘ĞĞ¡Ğ¢ĞĞ«Ğ™):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ¨Ğ°Ğ³ 1: ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ              â”‚
â”‚                                                     â”‚
â”‚  Dataset_1 [==================] â†’ params_1          â”‚
â”‚  Dataset_2 [==================] â†’ params_2          â”‚
â”‚  ...                                                â”‚
â”‚  Dataset_63 [=================] â†’ params_63         â”‚
â”‚                                                     â”‚
â”‚  Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑˆÑŒ Ğ’Ğ¡Ğ• Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ¨Ğ°Ğ³ 2: ĞŸĞ¾Ğ¸ÑĞº Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²                      â”‚
â”‚                                                     â”‚
â”‚  Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµÑˆÑŒ params_1..63                          â”‚
â”‚  Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµÑˆÑŒ Ñ‚Ğµ Ñ‡Ñ‚Ğ¾ "Ñ‡Ğ°Ñ‰Ğµ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ÑÑ‚ÑÑ"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ¨Ğ°Ğ³ 3: ĞŸÑ€Ğ¾Ğ³Ğ¾Ğ½ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ğ¼                    â”‚
â”‚                                                     â”‚
â”‚  Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµÑˆÑŒ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ½Ğ° Ğ¢Ğ•Ğ¥ Ğ–Ğ• Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¿Ğ¾Ğ´Ğ¾Ğ³Ğ½Ğ°Ğ½Ñ‹ Ğ¿Ğ¾Ğ´ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğµ âŒ
```

### ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ ÑÑ‚Ğ¾ overfitting:

1. **In-Sample Bias**: ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑˆÑŒ Ğ½Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… 2020-2024 â†’ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ "Ğ·Ğ°Ñ‚Ğ¾Ñ‡ĞµĞ½Ñ‹" Ğ¿Ğ¾Ğ´ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ 2020-2024
2. **Look-Ahead Bias**: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑˆÑŒ Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞµ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² (Ñ‚ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµÑˆÑŒ Ğ½Ğ° Ñ‚ĞµÑ… Ğ¶Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
3. **Data Snooping**: ĞœĞ½Ğ¾Ğ³Ğ¾ĞºÑ€Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ "Ğ½Ğ°Ğ¹Ñ‚Ğ¸-Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ‚ÑŒ" Ğ½Ğ° Ğ¾Ğ´Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
4. **Selection Bias**: "ĞĞ±Ñ‰Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹" = Ñ‚Ğµ Ñ‡Ñ‚Ğ¾ Ğ»ÑƒÑ‡ÑˆĞµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ’ ĞŸĞ ĞĞ¨Ğ›ĞĞœ

### Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (2025):
```
Backtest Sharpe:  3.5  â†  ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° 2020-2024
Live Sharpe:      0.2  â†  Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»Ñ 2025

Degradation: 94% âŒ
```

---

<a name="wfo-Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾"></a>
## 2. Walk-Forward Optimization (WFO) â€” Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾

### ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ: Ğ˜Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¢Ñ€ĞµĞ¹Ğ´Ğ¸Ğ½Ğ³Ğ°

Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ñ‚Ñ‹:
1. ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑˆÑŒ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğµ (backtest)
2. Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑˆÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ² live
3. Ğ§ĞµÑ€ĞµĞ· N Ğ¼ĞµÑÑÑ†ĞµĞ² â€” Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
4. Repeat

WFO Ğ´ĞµĞ»Ğ°ĞµÑ‚ Ğ¢Ğ Ğ–Ğ• Ğ½Ğ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

---

### 2.1 Anchored Walk-Forward

**Ğ¡Ñ…ĞµĞ¼Ğ°:**
```
ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚: [================================================]
                 2020-01        2022-01        2024-01    2025-01

Window 1:  [Train============][Test===]
           2020-01      2022-01     2022-07

Window 2:  [Train==================][Test===]
           2020-01            2022-07      2023-01

Window 3:  [Train==========================][Test===]
           2020-01                    2023-01     2023-07

Window 4:  [Train==================================][Test===]
           2020-01                          2023-07     2024-01
```

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- Train Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ **Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚** Ñ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¼ Ğ¾ĞºĞ½Ğ¾Ğ¼ (anchored Ğº Ğ½Ğ°Ñ‡Ğ°Ğ»Ñƒ)
- Test Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ (Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ 3-6 Ğ¼ĞµÑÑÑ†ĞµĞ²)
- Ğ˜Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ accumulation of data

**ĞšĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ:**
- Ğ•ÑĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ°Ğ»Ğ¾ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ
- Ğ•ÑĞ»Ğ¸ Ñ…Ğ¾Ñ‡ĞµÑˆÑŒ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ²ĞµÑÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¾Ğ¿Ñ‹Ñ‚
- Ğ•ÑĞ»Ğ¸ Ñ€Ñ‹Ğ½Ğ¾Ğº ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾

---

### 2.2 Rolling Walk-Forward

**Ğ¡Ñ…ĞµĞ¼Ğ°:**
```
ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚: [================================================]
                 2020-01        2022-01        2024-01    2025-01

Window 1:  [Train======][Test===]
           2020-01  2021-07  2022-01

Window 2:         [Train======][Test===]
                  2021-01  2022-07  2023-01

Window 3:                [Train======][Test===]
                         2022-01  2023-07  2024-01

Window 4:                       [Train======][Test===]
                                2023-01  2024-07  2025-01
```

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- Train Ğ¸ Test Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñ‹ **Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°**
- ĞĞºĞ½Ğ° **ÑĞºĞ¾Ğ»ÑŒĞ·ÑÑ‚** Ğ²Ğ¿ĞµÑ€Ñ‘Ğ´
- ĞĞµ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ (Ğ¸Ğ»Ğ¸ Ñ Ğ¼Ğ°Ğ»Ñ‹Ğ¼ overlap)

**ĞšĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ:**
- Ğ•ÑĞ»Ğ¸ Ñ…Ğ¾Ñ‡ĞµÑˆÑŒ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğº Ğ¢Ğ•ĞšĞ£Ğ©Ğ˜Ğœ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼ Ñ€Ñ‹Ğ½ĞºĞ°
- Ğ•ÑĞ»Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚ĞµÑ€ÑÑÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ (crypto, high-freq)
- Ğ•ÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ° Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ°Ñ†Ğ¸Ñ

---

### 2.3 ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ WFO

**Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¾ĞºĞ½Ğ° i:**

```python
# 1. ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Train (In-Sample)
train_data = data[window_i_train_start : window_i_train_end]
study = optuna.create_study(direction='maximize')
study.optimize(objective(train_data), n_trials=500)
best_params_i = study.best_params
IS_sharpe_i = study.best_value

# 2. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Test (Out-of-Sample)
test_data = data[window_i_test_start : window_i_test_end]
OOS_results_i = backtest(test_data, best_params_i)
OOS_sharpe_i = OOS_results_i['sharpe_ratio']
OOS_pnl_i = OOS_results_i['net_pnl']

# 3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
wfo_results.append({
    'window': i,
    'IS_sharpe': IS_sharpe_i,
    'OOS_sharpe': OOS_sharpe_i,
    'OOS_pnl': OOS_pnl_i,
    'params': best_params_i,
    'train_period': [window_i_train_start, window_i_train_end],
    'test_period': [window_i_test_start, window_i_test_end]
})
```

**Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°:**
```python
# Ğ¡ĞºĞ»ĞµĞ¸Ğ²Ğ°ĞµĞ¼ Ğ²ÑĞµ OOS Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñ‹ Ğ² ĞµĞ´Ğ¸Ğ½ÑƒÑ equity curve
full_OOS_equity = concatenate(OOS_pnl_1, OOS_pnl_2, ..., OOS_pnl_N)
WFO_sharpe = calculate_sharpe(full_OOS_equity)

# WFO Efficiency
WFO_efficiency = mean(OOS_sharpe_1..N) / mean(IS_sharpe_1..N)
```

---

### 2.4 ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¢Ğ²Ğ¾ĞµĞ³Ğ¾ Setup

#### Ğ•ÑĞ»Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ = 1M Ğ±Ğ°Ñ€Ğ¾Ğ² (â‰ˆ 2 Ğ³Ğ¾Ğ´Ğ° Ğ½Ğ° 1m, â‰ˆ 5 Ğ»ĞµÑ‚ Ğ½Ğ° 5m)

**Anchored WFO:**
```python
train_sizes = [0.40, 0.50, 0.60, 0.70, 0.80]  # % Ğ¾Ñ‚ total
test_size = 0.10  # Ğ¤Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ = 10%

# ĞĞºĞ½Ğ¾ 1: Train 40%, Test 10% (Ğ±Ğ°Ñ€Ğ¾Ğ² 400K-500K)
# ĞĞºĞ½Ğ¾ 2: Train 50%, Test 10% (Ğ±Ğ°Ñ€Ğ¾Ğ² 500K-600K)
# ĞĞºĞ½Ğ¾ 3: Train 60%, Test 10% (Ğ±Ğ°Ñ€Ğ¾Ğ² 600K-700K)
# ĞĞºĞ½Ğ¾ 4: Train 70%, Test 10% (Ğ±Ğ°Ñ€Ğ¾Ğ² 700K-800K)
# ĞĞºĞ½Ğ¾ 5: Train 80%, Test 10% (Ğ±Ğ°Ñ€Ğ¾Ğ² 800K-900K)
# ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 10% = Hold-out Ğ´Ğ»Ñ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ°
```

**Rolling WFO:**
```python
train_size = 400_000  # 40% Ğ±Ğ°Ñ€Ğ¾Ğ²
test_size = 100_000   # 10% Ğ±Ğ°Ñ€Ğ¾Ğ²
step = test_size      # ĞĞµ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ

# ĞĞºĞ½Ğ¾ 1: Train [0:400K], Test [400K:500K]
# ĞĞºĞ½Ğ¾ 2: Train [100K:500K], Test [500K:600K]
# ĞĞºĞ½Ğ¾ 3: Train [200K:600K], Test [600K:700K]
# ...
```

---

### 2.5 Embargo Period (Gap)

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:** Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ "Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼" Ğ¸ "Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»ĞµĞ¹" Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ²Ñ€ĞµĞ¼Ñ.

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:** Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ gap Ğ¼ĞµĞ¶Ğ´Ñƒ Train Ğ¸ Test.

```
Train [==========]  GAP [...] Test [====]
```

**Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸:**
- Gap = 5-10% Ğ¾Ñ‚ test_size
- Ğ”Ğ»Ñ crypto: 1-3 Ğ´Ğ½Ñ
- Ğ”Ğ»Ñ stocks: 1-5 Ğ´Ğ½ĞµĞ¹

```python
gap = int(test_size * 0.05)  # 5% Ğ¾Ñ‚ test size

test_start = train_end + gap
test_end = test_start + test_size
```

**Ğ—Ğ°Ñ‡ĞµĞ¼ Ğ½ÑƒĞ¶ĞµĞ½:**
- Ğ˜Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ information leakage (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ»Ğ°Ğ³Ğ¸ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
- Ğ ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½ĞµĞµ Ğ¸Ğ¼Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ live deployment
- Ğ£Ñ‡ĞµÑÑ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ° Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

---

<a name="temporal-validation"></a>
## 3. Temporal Validation Ñ Ğ Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ”Ğ°Ñ‚Ğ°Ğ¼Ğ¸

### 3.1 Ğ£ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸? Ğ­Ğ¢Ğ Ğ—ĞĞ›ĞĞ¢Ğ! ğŸ’°

**Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹:**
```
Dataset_1: BTCUSDT 2020-01 â†’ 2025-01
Dataset_2: ETHUSDT 2021-06 â†’ 2025-01
Dataset_3: SOLUSDT 2022-03 â†’ 2025-01
...
Dataset_63: APTUSDT 2023-01 â†’ 2025-01
```

### 3.2 Time-Based Cross-Validation

**Ğ˜Ğ´ĞµÑ:** ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ ĞĞ—ĞĞ«Ğ¥ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°Ñ… Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¾Ğ².

**ĞœĞµÑ‚Ğ¾Ğ´ 1: Train/Test Ğ¿Ğ¾ ĞºĞ°Ğ»ĞµĞ½Ğ´Ğ°Ñ€Ğ½Ñ‹Ğ¼ Ğ´Ğ°Ñ‚Ğ°Ğ¼**

```
Ğ’ÑĞµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñ‹ Ñ€Ğ°Ğ·Ğ±Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğ°Ğ¼:

Train:  2020-01-01 â†’ 2023-12-31  (Ğ²ÑĞµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ Ğ³Ğ´Ğµ ĞµÑÑ‚ÑŒ ÑÑ‚Ğ¸ Ğ´Ğ°Ñ‚Ñ‹)
Test:   2024-01-01 â†’ 2024-12-31  (out-of-sample Ğ³Ğ¾Ğ´)
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:**
```python
train_datasets = []
test_datasets = []

for dataset in all_datasets:
    # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ
    train_data = dataset[dataset['time'] < '2024-01-01']
    test_data = dataset[dataset['time'] >= '2024-01-01']

    if len(train_data) > min_bars:
        train_datasets.append(train_data)
    if len(test_data) > min_bars:
        test_datasets.append(test_data)

# ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° train_datasets
# Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° test_datasets
```

**ĞŸÑ€Ğ¾Ñ„Ğ¸Ñ‚:**
- ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ĞĞ• Ğ²Ğ¸Ğ´ĞµĞ»Ğ¸ 2024 Ğ³Ğ¾Ğ´ = true OOS test
- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ»Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ½Ğ° ĞĞĞ’Ğ«Ğ¥ Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ñ‹Ñ… ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑÑ…

---

**ĞœĞµÑ‚Ğ¾Ğ´ 2: Market Regime Validation**

**Ğ˜Ğ´ĞµÑ:** Ğ Ğ°Ğ·Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñ‹ = Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ñ€ĞµĞ¶Ğ¸Ğ¼Ñ‹ Ñ€Ñ‹Ğ½ĞºĞ° (bull/bear/sideways).

**Ğ¨Ğ°Ğ³ 1: ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¾Ğ²**
```python
def classify_regime(data):
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ñ€Ñ‹Ğ½ĞºĞ° Ğ´Ğ»Ñ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°"""
    returns = (data['close'][-1] - data['close'][0]) / data['close'][0]
    volatility = data['close'].std() / data['close'].mean()

    if returns > 0.5 and volatility < 0.1:
        return 'bull_low_vol'
    elif returns > 0.5 and volatility > 0.1:
        return 'bull_high_vol'
    elif returns < -0.2:
        return 'bear'
    else:
        return 'sideways'

# ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞ¹ Ğ²ÑĞµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñ‹
for dataset in all_datasets:
    dataset.regime = classify_regime(dataset)
```

**Ğ¨Ğ°Ğ³ 2: Train Ğ½Ğ° Ğ¾Ğ´Ğ½Ğ¸Ñ… Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ñ…, Test Ğ½Ğ° Ğ´Ñ€ÑƒĞ³Ğ¸Ñ…**
```python
# Train Ğ½Ğ° bull market
train_datasets = [d for d in all_datasets if d.regime.startswith('bull')]

# Test Ğ½Ğ° sideways/bear
test_datasets = [d for d in all_datasets if d.regime in ['sideways', 'bear']]

# ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
params = optimize_on_datasets(train_datasets)

# Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ: Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ»Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ½Ğ° Ğ”Ğ Ğ£Ğ“Ğ˜Ğ¥ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ñ…?
oos_results = test_on_datasets(test_datasets, params)
```

**ĞŸÑ€Ğ¾Ñ„Ğ¸Ñ‚:**
- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸
- ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ¾Ğ³Ğ½Ğ°Ğ½Ñ‹ Ğ¿Ğ¾Ğ´ Ğ¾Ğ´Ğ¸Ğ½ Ñ‚Ğ¸Ğ¿ Ñ€Ñ‹Ğ½ĞºĞ°

---

### 3.3 Combinatorial Purged Cross-Validation (Advanced)

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğ³Ğ¾ CV:** Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ¼ĞµÑÑ‚ Ğ°Ğ²Ñ‚Ğ¾ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ.

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:** Purging + Embargo.

```
Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸: [===========================================]

Fold 1 Train: [===]    [===]    [===]
Fold 1 Test:      [X][=][X]  â† Purge/Embargo
                      â†‘
                   Test period
```

**Purging:**
- Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ¸Ğ· Train Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞŸĞĞ¡Ğ›Ğ• Ñ‚Ğ¾Ñ‡ĞºĞ¸ Test (look-ahead bias)

**Embargo:**
- Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ¸Ğ· Train Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞŸĞ•Ğ Ğ•Ğ” Ñ‚Ğ¾Ñ‡ĞºĞ¾Ğ¹ Test (leakage Ñ‡ĞµÑ€ĞµĞ· overlapping trades)

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ:**
```python
def purged_cv_split(data, n_splits=5, embargo_pct=0.05):
    """
    Combinatorial Purged CV Ğ´Ğ»Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ€ÑĞ´Ğ¾Ğ²
    """
    n = len(data)
    test_size = n // (n_splits + 1)

    for i in range(n_splits):
        test_start = (i + 1) * test_size
        test_end = test_start + test_size

        # Test
        test_indices = range(test_start, test_end)

        # Purging: ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ÑĞ»Ğµ test_end
        # Embargo: ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ´ test_start
        embargo_size = int(test_size * embargo_pct)

        train_indices = list(range(0, test_start - embargo_size)) + \
                       list(range(test_end + embargo_size, n))

        yield train_indices, test_indices
```

---

<a name="cross-symbol-ensemble"></a>
## 4. Cross-Symbol Ensemble

### 4.1 ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ

**Ğ˜Ğ´ĞµÑ:** ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ ĞĞ—ĞĞ«Ğ¥ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ñ…, Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ñ‚Ğ¾Ğ¼ Ğ³Ğ´Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ».

### 4.2 Stratified K-Fold Ğ¿Ğ¾ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼

**Ğ¨Ğ°Ğ³ 1: Ğ¡Ñ‚Ñ€Ğ°Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ**

Ğ Ğ°Ğ·Ğ±ĞµĞ¹ 63 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ½Ğ° Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ¿Ğ¾ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°Ğ¼:

```python
def stratify_datasets(datasets):
    """Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ Ğ²Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ´Ñƒ"""
    groups = {
        'high_vol_bull': [],
        'high_vol_bear': [],
        'low_vol_bull': [],
        'low_vol_bear': [],
        'sideways': []
    }

    for dataset in datasets:
        vol = calculate_volatility(dataset)
        trend = calculate_trend(dataset)

        if vol > 0.15:
            if trend > 0.3:
                groups['high_vol_bull'].append(dataset)
            elif trend < -0.2:
                groups['high_vol_bear'].append(dataset)
        elif vol < 0.08:
            if trend > 0.2:
                groups['low_vol_bull'].append(dataset)
            elif trend < -0.1:
                groups['low_vol_bear'].append(dataset)
        else:
            groups['sideways'].append(dataset)

    return groups
```

**Ğ¨Ğ°Ğ³ 2: K-Fold Split**

```python
from sklearn.model_selection import KFold

# Ğ Ğ°Ğ·Ğ±Ğ¸Ñ‚ÑŒ Ğ½Ğ° 5 folds, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ñ€Ñ†Ğ¸Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(all_datasets)):
    train_datasets = [all_datasets[i] for i in train_idx]  # 50 datasets
    test_datasets = [all_datasets[i] for i in test_idx]    # 13 datasets

    print(f"Fold {fold_idx}: Train {len(train_datasets)}, Test {len(test_datasets)}")

    # ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° train
    params = optimize_on_multiple_datasets(train_datasets)

    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° test
    oos_metrics = validate_on_multiple_datasets(test_datasets, params)
```

### 4.3 Ensemble Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²

**ĞŸĞ¾ÑĞ»Ğµ 5 folds Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸ÑˆÑŒ 5 Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ¾Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²:**

```python
fold_1_params = {'stop_loss': 2.5, 'take_profit': 5.0, ...}
fold_2_params = {'stop_loss': 2.8, 'take_profit': 4.5, ...}
fold_3_params = {'stop_loss': 2.3, 'take_profit': 5.2, ...}
fold_4_params = {'stop_loss': 2.6, 'take_profit': 4.8, ...}
fold_5_params = {'stop_loss': 2.4, 'take_profit': 5.1, ...}
```

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ensemble:**

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ A: Median**
```python
final_params = {
    'stop_loss': np.median([2.5, 2.8, 2.3, 2.6, 2.4]) = 2.5,
    'take_profit': np.median([5.0, 4.5, 5.2, 4.8, 5.1]) = 5.0,
    ...
}
```

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ B: Weighted Ğ¿Ğ¾ OOS performance**
```python
weights = [oos_sharpe_1, oos_sharpe_2, ..., oos_sharpe_5]
weights = weights / sum(weights)

final_params = {
    'stop_loss': weighted_average([2.5, 2.8, ...], weights),
    ...
}
```

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ C: Intersection (ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹)**
```python
# Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ‡Ñ‚Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ½Ğ° Ğ’Ğ¡Ğ•Ğ¥ folds
# ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: ĞµÑĞ»Ğ¸ stop_loss=[2.3..2.8], Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ ÑĞµÑ€ĞµĞ´Ğ¸Ğ½Ñƒ 2.5
```

---

<a name="pipeline"></a>
## 5. ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Pipeline Ğ´Ğ»Ñ 63 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ²

### 5.1 ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Pipeline (ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ­Ğ¢ĞĞŸ 1: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ 63 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹                                      â”‚
â”‚ â€¢ ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ regime (bull/bear/sideways)              â”‚
â”‚ â€¢ Ğ¡Ñ‚Ñ€Ğ°Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ volatility                                â”‚
â”‚ â€¢ Ğ ĞµĞ·ĞµÑ€Ğ²Ğ°Ñ†Ğ¸Ñ Hold-out (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 10-15% Ğ²ÑĞµÑ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ²)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ­Ğ¢ĞĞŸ 2: Walk-Forward Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ (53 train datasets) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ For each dataset:                                            â”‚
â”‚   â€¢ Anchored WFO: 5 windows                                  â”‚
â”‚   â€¢ n_trials=500 per window                                  â”‚
â”‚   â€¢ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ best_params per window                        â”‚
â”‚   â€¢ Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ WFO Efficiency                               â”‚
â”‚                                                              â”‚
â”‚ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: 53 datasets Ã— 5 windows = 265 Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ¾Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ­Ğ¢ĞĞŸ 3: Cross-Symbol Validation (5-Fold)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Fold 1: Train 42 datasets â†’ Test 11 datasets                â”‚
â”‚ Fold 2: Train 42 datasets â†’ Test 11 datasets                â”‚
â”‚ Fold 3: Train 42 datasets â†’ Test 11 datasets                â”‚
â”‚ Fold 4: Train 42 datasets â†’ Test 11 datasets                â”‚
â”‚ Fold 5: Train 42 datasets â†’ Test 11 datasets                â”‚
â”‚                                                              â”‚
â”‚ Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ fold:                                            â”‚
â”‚   â€¢ Ğ£ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ‚ÑŒ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¸Ğ· WFO Ğ¿Ğ¾ train datasets     â”‚
â”‚   â€¢ Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° test datasets                              â”‚
â”‚   â€¢ Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ OOS metrics                                  â”‚
â”‚                                                              â”‚
â”‚ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: 5 Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ¾Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ­Ğ¢ĞĞŸ 4: Ensemble Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Median/Weighted average Ğ¸Ğ· 5 folds                         â”‚
â”‚ â€¢ Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ñ max Consistency Score                  â”‚
â”‚                                                              â”‚
â”‚ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: FINAL_PARAMS                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ­Ğ¢ĞĞŸ 5: Hold-out Test (Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ĞŸÑ€Ğ¾Ğ³Ğ½Ğ°Ñ‚ÑŒ FINAL_PARAMS Ğ½Ğ° Ğ²ÑĞµÑ… 63 hold-out Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°Ñ…        â”‚
â”‚ â€¢ Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Sharpe, PnL, MaxDD, Win Rate                   â”‚
â”‚ â€¢ Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ñ In-Sample Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸                            â”‚
â”‚                                                              â”‚
â”‚ Ğ•ÑĞ»Ğ¸ OOS_Sharpe / IS_Sharpe > 0.5:                          â”‚
â”‚   âœ… Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ°, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ² live                       â”‚
â”‚ Ğ˜Ğ½Ğ°Ñ‡Ğµ:                                                       â”‚
â”‚   âŒ Overfit, Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5.2 Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Pipeline (Proof-of-Concept)

Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ½Ğ° Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½, Ğ½Ğ°Ñ‡Ğ½Ğ¸ Ñ ÑÑ‚Ğ¾Ğ³Ğ¾:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ¿-10 ÑĞ°Ğ¼Ñ‹Ñ… Ğ»Ğ¸ĞºĞ²Ğ¸Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ² â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Rolling WFO Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ (3-4 Ğ¾ĞºĞ½Ğ°)        â”‚
â”‚    n_trials=300 per window                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Ğ£ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ‚ÑŒ best_params Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ¾ĞºĞ½Ğ°Ğ¼      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ WFO Efficiency                â”‚
â”‚    Ğ•ÑĞ»Ğ¸ > 0.5: Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ                   â”‚
â”‚    Ğ˜Ğ½Ğ°Ñ‡Ğµ: ÑƒĞ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… 53 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ…      â”‚
â”‚    (full data, Ğ±ĞµĞ· WFO)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Hold-out test Ğ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… 10% Ğ²ÑĞµÑ…      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ğ’Ñ€ĞµĞ¼Ñ: ~2-4 Ñ‡Ğ°ÑĞ° Ñ precomputed Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸
```

---

<a name="Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸"></a>
## 6. ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸

### 6.1 WFO Efficiency

**Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ°:**
```
WFO_Efficiency = mean(OOS_Sharpe[1..N]) / mean(IS_Sharpe[1..N])
```

Ğ“Ğ´Ğµ:
- `N` = ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ WFO Ğ¾ĞºĞ¾Ğ½
- `OOS_Sharpe[i]` = Sharpe Ğ½Ğ° out-of-sample Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğµ Ğ¾ĞºĞ½Ğ° i
- `IS_Sharpe[i]` = Sharpe Ğ½Ğ° in-sample Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğµ Ğ¾ĞºĞ½Ğ° i

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
| WFO Efficiency | ĞÑ†ĞµĞ½ĞºĞ° | Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ |
|----------------|--------|----------|
| > 0.7 | ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾ | ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ñ‹ |
| 0.5 - 0.7 | Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ | ĞŸÑ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ |
| 0.3 - 0.5 | ĞŸĞ¾ÑÑ€ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ | Ğ•ÑÑ‚ÑŒ degradation, Ğ½ÑƒĞ¶Ğ½Ğ° Ğ¾ÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ |
| < 0.3 | ĞŸĞ»Ğ¾Ñ…Ğ¾ | Ğ¡Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ overfit, Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ |

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ñ€Ğ°ÑÑ‡Ñ‘Ñ‚Ğ°:**
```python
wfo_results = [
    {'IS_sharpe': 2.5, 'OOS_sharpe': 1.8},
    {'IS_sharpe': 2.8, 'OOS_sharpe': 1.5},
    {'IS_sharpe': 3.0, 'OOS_sharpe': 2.0},
    {'IS_sharpe': 2.6, 'OOS_sharpe': 1.6},
]

mean_IS = (2.5 + 2.8 + 3.0 + 2.6) / 4 = 2.725
mean_OOS = (1.8 + 1.5 + 2.0 + 1.6) / 4 = 1.725

WFO_Efficiency = 1.725 / 2.725 = 0.633  â† Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾! âœ…
```

---

### 6.2 Consistency Score

**Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ°:**
```
Consistency = count(positive_OOS_periods) / total_periods
```

Ğ“Ğ´Ğµ:
- `positive_OOS_periods` = ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¾ĞºĞ¾Ğ½/folds Ğ³Ğ´Ğµ OOS_Sharpe > 0 (Ğ¸Ğ»Ğ¸ OOS_PnL > 0)

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
| Consistency | ĞÑ†ĞµĞ½ĞºĞ° | Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ |
|-------------|--------|----------|
| = 1.0 | Ğ˜Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾ | Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ’Ğ¡Ğ•Ğ¥ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°Ñ… |
| > 0.8 | ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾ | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ |
| 0.6 - 0.8 | Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ | Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğµ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¾Ğ² |
| < 0.6 | ĞŸĞ»Ğ¾Ñ…Ğ¾ | ĞĞµ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ |

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:**
```python
oos_sharpes = [1.5, -0.2, 2.0, 1.8, 0.5]
positive_count = sum([1 for s in oos_sharpes if s > 0])  # = 4
total = len(oos_sharpes)  # = 5

Consistency = 4 / 5 = 0.8  â† ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾! âœ…
```

---

### 6.3 Degradation Ratio

**Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ°:**
```
Degradation = 1 - (mean_OOS_metric / mean_IS_metric)
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
| Degradation | ĞÑ†ĞµĞ½ĞºĞ° | Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ |
|-------------|--------|----------|
| < 20% | ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾ | ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€Ñ performance |
| 20-40% | Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ | ĞŸÑ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ñ‹Ğ¹ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ |
| 40-60% | ĞŸĞ¾ÑÑ€ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ | Ğ—Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ degradation |
| > 60% | ĞŸĞ»Ğ¾Ñ…Ğ¾ | Ğ¡Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ overfit |

**Ğ¡Ğ²ÑĞ·ÑŒ Ñ WFO Efficiency:**
```
Degradation â‰ˆ 1 - WFO_Efficiency
```

---

### 6.4 Stability (Coefficient of Variation)

**Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ°:**
```
Stability = std(OOS_Sharpe[1..N]) / mean(OOS_Sharpe[1..N])
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
| Stability (CV) | ĞÑ†ĞµĞ½ĞºĞ° | Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ |
|----------------|--------|----------|
| < 0.3 | ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾ | Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ |
| 0.3 - 0.5 | Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ | Ğ£Ğ¼ĞµÑ€ĞµĞ½Ğ½Ğ°Ñ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ |
| 0.5 - 1.0 | ĞŸĞ¾ÑÑ€ĞµĞ´ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ |
| > 1.0 | ĞŸĞ»Ğ¾Ñ…Ğ¾ | ĞĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ |

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:**
```python
oos_sharpes = [1.5, 1.8, 1.6, 1.7, 1.9]
mean_sharpe = 1.7
std_sharpe = 0.14

Stability = 0.14 / 1.7 = 0.082  â† ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾! âœ…
```

---

### 6.5 Composite Robustness Score

**Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ°:**
```
Robustness_Score = (
    0.4 * WFO_Efficiency +
    0.3 * Consistency +
    0.2 * (1 - Stability) +
    0.1 * (1 - abs(Degradation))
)
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
| Score | ĞÑ†ĞµĞ½ĞºĞ° |
|-------|--------|
| > 0.7 | ĞÑ‡ĞµĞ½ÑŒ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ |
| 0.5-0.7 | Ğ Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ°Ñ |
| 0.3-0.5 | Ğ£Ğ¼ĞµÑ€ĞµĞ½Ğ½Ğ¾ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ°Ñ |
| < 0.3 | ĞĞµ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ°Ñ |

---

<a name="Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"></a>
## 7. ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

### 7.1 ĞšĞ¾Ğ´: Anchored WFO Ğ½Ğ° Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ

```python
from src.optimization.fast_optimizer import FastStrategyOptimizer
import numpy as np

def run_anchored_wfo(data_path, strategy_name, symbol):
    """
    Anchored Walk-Forward Optimization Ğ½Ğ° Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ
    """
    # 1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    from src.data.klines_handler import VectorizedKlinesHandler
    handler = VectorizedKlinesHandler()
    full_data = handler.load_klines(data_path)
    n = len(full_data)

    # 2. ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¾ĞºĞ¾Ğ½
    train_sizes = [0.40, 0.50, 0.60, 0.70, 0.80]
    test_size = 0.10
    holdout_size = 0.10

    # Ğ ĞµĞ·ĞµÑ€Ğ²Ğ¸Ñ€ÑƒĞµĞ¼ hold-out
    holdout_start = int(n * (1 - holdout_size))
    data_for_wfo = full_data[:holdout_start]
    holdout_data = full_data[holdout_start:]

    wfo_results = []

    # 3. WFO Loop
    for i, train_pct in enumerate(train_sizes):
        print(f"\n{'='*60}")
        print(f"WFO Window {i+1}/{len(train_sizes)}")
        print(f"{'='*60}")

        train_end = int(len(data_for_wfo) * train_pct)
        test_start = train_end
        test_end = test_start + int(n * test_size)

        if test_end > len(data_for_wfo):
            print(f"[SKIP] Not enough data for test period")
            break

        train_data = data_for_wfo[:train_end]
        test_data = data_for_wfo[test_start:test_end]

        print(f"Train: {len(train_data):,} bars | Test: {len(test_data):,} bars")

        # 3.1 ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Train
        optimizer = FastStrategyOptimizer(
            strategy_name=strategy_name,
            data_path=data_path,  # Ğ‘ÑƒĞ´ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞµÑˆ
            symbol=symbol
        )

        # Ğ¥Ğ°Ğº: Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ğ¼ cached_data Ğ½Ğ° train_data
        optimizer.cached_data['full'] = train_data

        train_results = optimizer.optimize(
            n_trials=500,
            objective_metric='sharpe_ratio',
            min_trades=10,
            max_drawdown_threshold=50.0,
            data_slice='full'
        )

        best_params = train_results['best_params']
        is_sharpe = train_results['best_value']

        print(f"[Train] Best Sharpe: {is_sharpe:.3f}")
        print(f"[Train] Best Params: {best_params}")

        # 3.2 Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Test (OOS)
        from src.strategies.base_strategy import StrategyRegistry
        strategy_class = StrategyRegistry.get_strategy(strategy_name)
        strategy = strategy_class(symbol=symbol, **best_params)

        oos_results = strategy.vectorized_process_dataset(test_data)
        oos_sharpe = oos_results.get('sharpe_ratio', 0)
        oos_pnl = oos_results.get('net_pnl', 0)
        oos_trades = oos_results.get('total', 0)

        print(f"[Test]  OOS Sharpe: {oos_sharpe:.3f}")
        print(f"[Test]  OOS PnL: {oos_pnl:.2f}")
        print(f"[Test]  OOS Trades: {oos_trades}")

        wfo_results.append({
            'window': i + 1,
            'train_bars': len(train_data),
            'test_bars': len(test_data),
            'IS_sharpe': is_sharpe,
            'OOS_sharpe': oos_sharpe,
            'OOS_pnl': oos_pnl,
            'OOS_trades': oos_trades,
            'params': best_params
        })

    # 4. WFO ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
    is_sharpes = [r['IS_sharpe'] for r in wfo_results]
    oos_sharpes = [r['OOS_sharpe'] for r in wfo_results]

    wfo_efficiency = np.mean(oos_sharpes) / np.mean(is_sharpes)
    consistency = sum(1 for s in oos_sharpes if s > 0) / len(oos_sharpes)
    stability = np.std(oos_sharpes) / np.mean(oos_sharpes) if np.mean(oos_sharpes) != 0 else 999

    print(f"\n{'='*60}")
    print(f"WFO SUMMARY")
    print(f"{'='*60}")
    print(f"WFO Efficiency: {wfo_efficiency:.3f}")
    print(f"Consistency:    {consistency:.2%}")
    print(f"Stability (CV): {stability:.3f}")

    # 5. Hold-out Test (Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ½Ğ° unseen data)
    print(f"\n{'='*60}")
    print(f"HOLD-OUT TEST (Final Validation)")
    print(f"{'='*60}")

    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ median Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸Ğ· Ğ²ÑĞµÑ… Ğ¾ĞºĞ¾Ğ½
    from statistics import median
    all_param_keys = wfo_results[0]['params'].keys()
    median_params = {}
    for key in all_param_keys:
        values = [r['params'][key] for r in wfo_results]
        if isinstance(values[0], (int, float)):
            median_params[key] = median(values)
        else:
            # Categorical: Ğ²Ğ¾Ğ·ÑŒĞ¼Ñ‘Ğ¼ ÑĞ°Ğ¼Ñ‹Ğ¹ Ñ‡Ğ°ÑÑ‚Ñ‹Ğ¹
            from collections import Counter
            median_params[key] = Counter(values).most_common(1)[0][0]

    print(f"Median Params: {median_params}")

    strategy_final = strategy_class(symbol=symbol, **median_params)
    holdout_results = strategy_final.vectorized_process_dataset(holdout_data)

    holdout_sharpe = holdout_results.get('sharpe_ratio', 0)
    holdout_pnl = holdout_results.get('net_pnl', 0)

    print(f"Hold-out Sharpe: {holdout_sharpe:.3f}")
    print(f"Hold-out PnL:    {holdout_pnl:.2f}")
    print(f"Hold-out vs IS:  {holdout_sharpe / np.mean(is_sharpes):.2%}")

    return {
        'wfo_results': wfo_results,
        'wfo_efficiency': wfo_efficiency,
        'consistency': consistency,
        'stability': stability,
        'median_params': median_params,
        'holdout_sharpe': holdout_sharpe,
        'holdout_pnl': holdout_pnl
    }

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
result = run_anchored_wfo(
    data_path='data/BTCUSDT_1m.parquet',
    strategy_name='ported_from_example',
    symbol='BTCUSDT'
)
```

---

### 7.2 ĞšĞ¾Ğ´: Cross-Symbol Validation

```python
def cross_symbol_validation(datasets, strategy_name, n_folds=5):
    """
    K-Fold Cross-Validation Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼
    """
    from sklearn.model_selection import KFold
    import numpy as np

    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    fold_results = []

    for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(datasets)):
        print(f"\n{'='*60}")
        print(f"FOLD {fold_idx + 1}/{n_folds}")
        print(f"{'='*60}")

        train_datasets = [datasets[i] for i in train_idx]
        test_datasets = [datasets[i] for i in test_idx]

        print(f"Train: {len(train_datasets)} datasets")
        print(f"Test:  {len(test_datasets)} datasets")

        # 1. ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ train dataset
        all_train_params = []
        for dataset in train_datasets:
            optimizer = FastStrategyOptimizer(
                strategy_name=strategy_name,
                data_path=dataset['path'],
                symbol=dataset['symbol']
            )
            results = optimizer.optimize(
                n_trials=300,  # ĞœĞµĞ½ÑŒÑˆĞµ trials Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸
                objective_metric='sharpe_ratio'
            )
            all_train_params.append(results['best_params'])

        # 2. Ğ£ÑÑ€ĞµĞ´Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
        param_keys = all_train_params[0].keys()
        median_params = {}
        for key in param_keys:
            values = [p[key] for p in all_train_params]
            if isinstance(values[0], (int, float)):
                median_params[key] = np.median(values)
            else:
                from collections import Counter
                median_params[key] = Counter(values).most_common(1)[0][0]

        print(f"Fold {fold_idx+1} Median Params: {median_params}")

        # 3. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° test datasets
        strategy_class = StrategyRegistry.get_strategy(strategy_name)
        test_sharpes = []
        test_pnls = []

        for dataset in test_datasets:
            handler = VectorizedKlinesHandler()
            data = handler.load_klines(dataset['path'])

            strategy = strategy_class(symbol=dataset['symbol'], **median_params)
            results = strategy.vectorized_process_dataset(data)

            test_sharpes.append(results.get('sharpe_ratio', 0))
            test_pnls.append(results.get('net_pnl', 0))

        fold_oos_sharpe = np.mean(test_sharpes)
        fold_consistency = sum(1 for s in test_sharpes if s > 0) / len(test_sharpes)

        print(f"Fold {fold_idx+1} OOS Sharpe: {fold_oos_sharpe:.3f}")
        print(f"Fold {fold_idx+1} Consistency: {fold_consistency:.2%}")

        fold_results.append({
            'fold': fold_idx + 1,
            'median_params': median_params,
            'oos_sharpe': fold_oos_sharpe,
            'oos_pnls': test_pnls,
            'consistency': fold_consistency
        })

    # 4. Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒÑÑ€ĞµĞ´Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ folds
    print(f"\n{'='*60}")
    print(f"CROSS-VALIDATION SUMMARY")
    print(f"{'='*60}")

    all_oos_sharpes = [f['oos_sharpe'] for f in fold_results]
    avg_oos_sharpe = np.mean(all_oos_sharpes)
    avg_consistency = np.mean([f['consistency'] for f in fold_results])

    print(f"Average OOS Sharpe: {avg_oos_sharpe:.3f}")
    print(f"Average Consistency: {avg_consistency:.2%}")

    # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ = median Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ folds
    all_fold_params = [f['median_params'] for f in fold_results]
    param_keys = all_fold_params[0].keys()
    final_params = {}
    for key in param_keys:
        values = [p[key] for p in all_fold_params]
        if isinstance(values[0], (int, float)):
            final_params[key] = np.median(values)
        else:
            from collections import Counter
            final_params[key] = Counter(values).most_common(1)[0][0]

    print(f"\nFinal Ensemble Params: {final_params}")

    return {
        'fold_results': fold_results,
        'avg_oos_sharpe': avg_oos_sharpe,
        'avg_consistency': avg_consistency,
        'final_params': final_params
    }

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
datasets = [
    {'path': 'data/BTCUSDT.parquet', 'symbol': 'BTCUSDT'},
    {'path': 'data/ETHUSDT.parquet', 'symbol': 'ETHUSDT'},
    # ... all 63 datasets
]

cv_results = cross_symbol_validation(
    datasets=datasets,
    strategy_name='ported_from_example',
    n_folds=5
)
```

---

<a name="Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ"></a>
## 8. Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

### 8.1 Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ A: ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ âœ…

**ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸:**
```
WFO Efficiency:  0.68
Consistency:     85%
Stability:       0.32
Hold-out Sharpe: 1.8 (Ğ¿Ñ€Ğ¸ IS Sharpe: 2.5)
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
- âœ… WFO Efficiency > 0.5 â†’ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ñ‹
- âœ… Consistency 85% â†’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğµ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¾Ğ²
- âœ… Stability < 0.5 â†’ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âœ… Hold-out degradation 28% â†’ Ğ¿Ñ€Ğ¸ĞµĞ¼Ğ»ĞµĞ¼Ğ¾

**Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ:**
â†’ Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğº live trading Ñ ÑÑ‚Ğ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸

---

### 8.2 Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ B: Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ âš ï¸

**ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸:**
```
WFO Efficiency:  0.42
Consistency:     60%
Stability:       0.85
Hold-out Sharpe: 0.5 (Ğ¿Ñ€Ğ¸ IS Sharpe: 2.8)
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
- âš ï¸ WFO Efficiency < 0.5 â†’ ĞµÑÑ‚ÑŒ overfit
- âš ï¸ Consistency 60% â†’ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğµ Ğ½Ğ° Ğ²ÑĞµÑ… Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°Ñ…
- âš ï¸ Stability > 0.5 â†’ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
- âŒ Hold-out degradation 82% â†’ ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ degradation

**Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ:**
â†’ Ğ£Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ:
  - Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚ÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
  - Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ constraints (min_trades, max_DD)
  - Ğ˜Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ objective Ğ½Ğ° Ğ±Ğ¾Ğ»ĞµĞµ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½ÑƒÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ

---

### 8.3 Ğ¡Ñ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹ C: ĞŸĞ»Ğ¾Ñ…Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ âŒ

**ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸:**
```
WFO Efficiency:  0.18
Consistency:     35%
Stability:       1.50
Hold-out Sharpe: -0.2 (Ğ¿Ñ€Ğ¸ IS Sharpe: 3.2)
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
- âŒ WFO Efficiency < 0.3 â†’ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ overfit
- âŒ Consistency < 50% â†’ Ğ½Ğµ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°
- âŒ Stability > 1.0 â†’ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°
- âŒ Hold-out Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ â†’ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

**Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ:**
â†’ Ğ Ğ°Ğ´Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ:
  1. Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğº Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¹ Ğ»Ğ¾Ğ³Ğ¸ĞºĞµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸
  2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ĞµÑÑ‚ÑŒ Ğ»Ğ¸ edge Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ (simple buy-hold benchmark)
  3. Ğ£Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ 2-3 Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
  4. ĞŸĞµÑ€ĞµĞ¾ÑĞ¼Ñ‹ÑĞ»Ğ¸Ñ‚ÑŒ entry/exit Ğ»Ğ¾Ğ³Ğ¸ĞºÑƒ

---

### 8.4 Red Flags (ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Overfit)

ğŸš© **Red Flag #1:** IS Sharpe > 4.0
- Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ´Ğ¾Ğ¹
- Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ğ½ĞºĞ° Ğ¿Ğ¾Ğ´ ÑˆÑƒĞ¼

ğŸš© **Red Flag #2:** OOS Sharpe / IS Sharpe < 0.2
- Massive degradation
- ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑÑÑ‚ÑÑ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ

ğŸš© **Red Flag #3:** Ğ‘Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹ Ñ€Ğ°Ğ·Ğ±Ñ€Ğ¾Ñ OOS Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¿Ğ¾ Ğ¾ĞºĞ½Ğ°Ğ¼
- Window 1: Sharpe 2.5
- Window 2: Sharpe -0.5
- Window 3: Sharpe 3.0
â†’ ĞĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ = overfit Ğ½Ğ° ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹

ğŸš© **Red Flag #4:** ĞœĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ
- > 7-8 Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² = Ñ€Ğ¸ÑĞº Ğ¿ĞµÑ€ĞµĞ¿Ğ¾Ğ´Ğ³Ğ¾Ğ½ĞºĞ¸
- Curse of dimensionality

ğŸš© **Red Flag #5:** ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ½Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ°
- stop_loss = 0.51 (Ğ¿Ñ€Ğ¸ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ 0.5-5.0)
- take_profit = 7.99 (Ğ¿Ñ€Ğ¸ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ 1.0-8.0)
â†’ Optuna "ÑƒĞ¿ĞµÑ€ÑÑ" Ğ² Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ = Ğ¿Ğ»Ğ¾Ñ…Ğ¾Ğ¹ sign

---

<a name="Ñ‡ĞµĞºĞ»Ğ¸ÑÑ‚"></a>
## 9. Ğ§ĞµĞºĞ»Ğ¸ÑÑ‚ Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹

### Ğ¤Ğ°Ğ·Ğ° 1: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° (1-2 Ñ‡Ğ°ÑĞ°)

- [ ] Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ 63 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°
- [ ] ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ¸, outliers)
- [ ] ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ volatility Ğ¸ trend
- [ ] Ğ—Ğ°Ñ€ĞµĞ·ĞµÑ€Ğ²Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Hold-out (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 10-15%)
- [ ] Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ¿-10 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ² Ğ´Ğ»Ñ proof-of-concept

### Ğ¤Ğ°Ğ·Ğ° 2: WFO Ğ½Ğ° Ñ‚Ğ¾Ğ¿-10 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ… (2-4 Ñ‡Ğ°ÑĞ°)

- [ ] ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ WFO (train/test sizes, embargo)
- [ ] Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Anchored WFO Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ Ğ¸Ğ· 10
- [ ] Ğ¡Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ
- [ ] Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ WFO Efficiency Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾
- [ ] **Decision Point:** Ğ•ÑĞ»Ğ¸ avg WFO Efficiency < 0.4 â†’ ÑƒĞ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ‚ÑŒ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ

### Ğ¤Ğ°Ğ·Ğ° 3: Cross-Symbol Validation (3-5 Ñ‡Ğ°ÑĞ¾Ğ²)

- [ ] Ğ Ğ°Ğ·Ğ±Ğ¸Ñ‚ÑŒ 63 Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ½Ğ° 5 folds (ÑÑ‚Ñ€Ğ°Ñ‚Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾)
- [ ] Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ fold: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° train, Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° test
- [ ] Ğ¡Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ OOS Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ folds
- [ ] Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Consistency Score
- [ ] Ensemble Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² (median/weighted)

### Ğ¤Ğ°Ğ·Ğ° 4: Hold-out Test (30 Ğ¼Ğ¸Ğ½)

- [ ] ĞŸÑ€Ğ¾Ğ³Ğ½Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ½Ğ° Hold-out Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- [ ] Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Hold-out metrics Ñ IS metrics
- [ ] Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Degradation
- [ ] **Decision Point:** Ğ•ÑĞ»Ğ¸ Hold-out Sharpe / IS Sharpe > 0.5 â†’ GO LIVE

### Ğ¤Ğ°Ğ·Ğ° 5: Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¸ ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

- [ ] Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ² JSON/CSV
- [ ] Ğ—Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
- [ ] Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ»Ğ°Ğ½ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° live performance
- [ ] Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ alerts (ĞµÑĞ»Ğ¸ live Sharpe Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ğ½Ğ° 50% Ğ¾Ñ‚ OOS)

---

## 10. Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¢ĞµÑ…Ğ½Ğ¸ĞºĞ¸ (Advanced)

### 10.1 Monte Carlo Simulation

**Ğ˜Ğ´ĞµÑ:** Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² entry Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ PnL.

```python
def monte_carlo_validation(data, params, n_simulations=100):
    """
    Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Â±10% ÑˆÑƒĞ¼ Ğº entry Ñ†ĞµĞ½Ğµ Ğ¸ ÑĞ¸Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒĞµÑ‚ trades
    """
    pnls = []
    for i in range(n_simulations):
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ ÑˆÑƒĞ¼ Ğº entry
        noise = np.random.uniform(-0.1, 0.1, size=len(data))
        data_noisy = data.copy()
        data_noisy['entry_price'] = data['close'] * (1 + noise)

        strategy = Strategy(**params)
        results = strategy.backtest(data_noisy)
        pnls.append(results['net_pnl'])

    # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
    mean_pnl = np.mean(pnls)
    std_pnl = np.std(pnls)
    pct_positive = sum(1 for p in pnls if p > 0) / len(pnls)

    print(f"Monte Carlo PnL: {mean_pnl:.2f} Â± {std_pnl:.2f}")
    print(f"% Positive: {pct_positive:.1%}")

    return {
        'mean_pnl': mean_pnl,
        'std_pnl': std_pnl,
        'pct_positive': pct_positive
    }
```

**Ğ˜Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ñ:**
- Ğ•ÑĞ»Ğ¸ `pct_positive > 80%` â†’ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ° Ğº timing
- Ğ•ÑĞ»Ğ¸ `std_pnl / mean_pnl < 0.5` â†’ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°Ñ

---

### 10.2 Parameter Sensitivity Analysis

**Ğ˜Ğ´ĞµÑ:** ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğº Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ².

```python
def sensitivity_analysis(data, base_params, param_to_test='stop_loss'):
    """
    Ğ’Ğ°Ñ€ÑŒĞ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ Â±20% Ğ¸ ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚ Ğ½Ğ° Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Sharpe
    """
    base_value = base_params[param_to_test]
    variations = np.linspace(base_value * 0.8, base_value * 1.2, 10)

    sharpes = []
    for value in variations:
        params = base_params.copy()
        params[param_to_test] = value

        strategy = Strategy(**params)
        results = strategy.backtest(data)
        sharpes.append(results['sharpe_ratio'])

    # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    import matplotlib.pyplot as plt
    plt.plot(variations, sharpes)
    plt.xlabel(param_to_test)
    plt.ylabel('Sharpe Ratio')
    plt.title(f'Sensitivity: {param_to_test}')
    plt.show()

    # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ°: ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ğ¸
    cv = np.std(sharpes) / np.mean(sharpes)
    print(f"Coefficient of Variation: {cv:.3f}")

    # Ğ•ÑĞ»Ğ¸ CV < 0.2 â†’ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ Ğ½Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµĞ½ (robust)
    # Ğ•ÑĞ»Ğ¸ CV > 0.5 â†’ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ (Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾!)

    return cv
```

---

### 10.3 Regime-Based Hold-out

**Ğ˜Ğ´ĞµÑ:** ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ»Ğ¸ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ² Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ñ….

```python
def regime_holdout_test(datasets, params, strategy_name):
    """
    Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµÑ‚ hold-out Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°Ğ¼ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾
    """
    regimes = {
        'bull': [],
        'bear': [],
        'sideways': []
    }

    for dataset in datasets:
        regime = classify_regime(dataset['holdout_data'])
        regimes[regime].append(dataset['holdout_data'])

    results = {}
    for regime, datas in regimes.items():
        sharpes = []
        for data in datas:
            strategy = Strategy(**params)
            res = strategy.backtest(data)
            sharpes.append(res['sharpe_ratio'])

        results[regime] = {
            'mean_sharpe': np.mean(sharpes),
            'consistency': sum(1 for s in sharpes if s > 0) / len(sharpes)
        }

        print(f"{regime.upper()}: Sharpe {results[regime]['mean_sharpe']:.2f}, Consistency {results[regime]['consistency']:.1%}")

    return results
```

**Ğ¦ĞµĞ»ÑŒ:** Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ÑŒÑÑ Ñ‡Ñ‚Ğ¾ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² bull, Ğ½Ğ¾ Ğ¸ Ğ² bear/sideways.

---

## 11. Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ

### ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ĞŸÑ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ Ğ Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ¾Ğ¹ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:

1. **Never optimize on data you will test on** â† Ğ—Ğ¾Ğ»Ğ¾Ñ‚Ğ¾Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾
2. **Time-based validation** â† Ğ£Ñ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ğ¹ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¿Ñ€Ğ¸Ñ€Ğ¾Ğ´Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
3. **Multiple validation layers** â† WFO + Cross-Symbol + Hold-out
4. **Conservative metrics** â† Ğ•ÑĞ»Ğ¸ ÑĞ¾Ğ¼Ğ½ĞµĞ²Ğ°ĞµÑˆÑŒÑÑ, ÑƒĞ¿Ñ€Ğ¾ÑÑ‚Ğ¸
5. **Accept degradation** â† OOS Ğ²ÑĞµĞ³Ğ´Ğ° Ñ…ÑƒĞ¶Ğµ IS, ÑÑ‚Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾

### Ğ ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ:

| Ğ­Ñ‚Ğ°Ğ¿ | Sharpe Ratio |
|------|--------------|
| In-Sample (IS) | 2.5 |
| Out-of-Sample (OOS) WFO | 1.5 - 1.8 |
| Hold-out | 1.2 - 1.5 |
| Live Trading | 0.8 - 1.2 |

**Degradation 50-70% Ğ¾Ñ‚ IS Ğº Live â€” ÑÑ‚Ğ¾ ĞĞĞ ĞœĞĞ›Ğ¬ĞĞ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ°ÑÑ‚Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸.**

Ğ•ÑĞ»Ğ¸ live results Ğ±Ğ»Ğ¸Ğ·ĞºĞ¸ Ğº OOS/Hold-out â†’ Ñ‚Ñ‹ Ğ²ÑÑ‘ ÑĞ´ĞµĞ»Ğ°Ğ» Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾! âœ…

---

## ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹ Ğ¸ Ğ ĞµÑÑƒÑ€ÑÑ‹

**Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°:**
- "Advances in Financial Machine Learning" by Marcos Lopez de Prado (Ğ³Ğ»Ğ°Ğ²Ğ° Ğ¿Ñ€Ğ¾ Cross-Validation)
- "Evidence-Based Technical Analysis" by David Aronson
- "Quantitative Trading" by Ernest Chan (Ğ³Ğ»Ğ°Ğ²Ğ° Ğ¿Ñ€Ğ¾ Walk-Forward)

**Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹:**
- Ğ¢Ğ²Ğ¾Ğ¹ `wfo_optimizer.py` ÑƒĞ¶Ğµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ WFO
- `fast_optimizer.py` Ñ precomputed Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸
- ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ WFO equity curves Ñ `matplotlib`

---

**Ğ’ĞµÑ€ÑĞ¸Ñ:** 1.0
**ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ:** 2025-10-11
**Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸:** ĞĞ°Ñ‡Ğ½Ğ¸ Ñ Ğ¤Ğ°Ğ·Ñ‹ 1 Ñ‡ĞµĞºĞ»Ğ¸ÑÑ‚Ğ° â†‘
